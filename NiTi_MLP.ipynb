{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import matplotlib.pyplot as plt\n",
    "#from neupy.algorithms import RBFKMeans\n",
    "#from neupy.algorithms import GRNN\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import svm\n",
    "from pyGRNN import GRNN\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn import linear_model\n",
    "import seaborn as sn\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from skopt import BayesSearchCV\n",
    "import warnings\n",
    "import heapq\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from scipy.stats import randint as sp_randint\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to report best scores+timings\n",
    "def report_perf(optimizer, X, y, title):\n",
    "    optimizer.fit(X, y)\n",
    "    print(title, \"best CV score:\", optimizer.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Multilayer perceptron (MLP)\n",
    "'''\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "file_name = 'NiTi_PhaseDatesets.xlsx'\n",
    "dataset = pd.read_excel(file_name, header=0)\n",
    "\n",
    "#print(dataset)\n",
    "x1 = dataset['P(W)'].values\n",
    "x2 = dataset['V(mm/s)'].values\n",
    "x3 = dataset['h(um)'].values\n",
    "# x4 = dataset['t(um)'].values\n",
    "x5 = dataset['LED(J/mm)'].values\n",
    "# x6 = dataset['SED(J/mm2)'].values\n",
    "x7 = dataset['VED(J/mm3)'].values\n",
    "x8 = dataset['Ni'].values\n",
    "# x9 = dataset['Ti'].values\n",
    "x10 = dataset['Dmin'].values\n",
    "x11 = dataset['Dmax'].values\n",
    "x12 = dataset['D10'].values\n",
    "# x13 = dataset['D50'].values\n",
    "x14 = dataset['D90'].values\n",
    "\n",
    "\n",
    "y1 = dataset['Ms'].values\n",
    "y2 = dataset['Mf'].values\n",
    "y3 = dataset['As'].values\n",
    "y4 = dataset['Af'].values\n",
    "X = np.column_stack((x1.reshape(-1, 1), \n",
    "                     x2.reshape(-1, 1), \n",
    "                     x3.reshape(-1, 1),\n",
    "                #      x4.reshape(-1, 1), \n",
    "                     x5.reshape(-1, 1),\n",
    "                #      x6.reshape(-1, 1),\n",
    "                     x7.reshape(-1, 1),\n",
    "                     x8.reshape(-1, 1),\n",
    "                #      x9.reshape(-1, 1),\n",
    "                     x10.reshape(-1, 1),\n",
    "                     x11.reshape(-1, 1),\n",
    "                     x12.reshape(-1, 1),\n",
    "                #      x13.reshape(-1, 1),\n",
    "                     x14.reshape(-1, 1),\n",
    "                \n",
    "                     ))\n",
    "\n",
    "Y = np.column_stack((y1,y2, y3, y4))\n",
    "\n",
    "\n",
    "MaxGlobal = 0\n",
    "MaxGlobal_Score = 0\n",
    "MaxGlobal_Score_train = 0\n",
    "Max_local = 0\n",
    "\n",
    "\n",
    "\n",
    "MLP_scores = {'CV': [], 'R2': [],  'R2_train': []}\n",
    "Accuracy_MLP = []\n",
    "MLP_RMSE = []\n",
    "for j in range(50):\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=j)\n",
    "    xscaler = preprocessing.StandardScaler()\n",
    "    X_train_standard = xscaler.fit_transform(X_train)\n",
    "    X_test_standard = xscaler.transform(X_test)\n",
    "\n",
    "    yscaler = preprocessing.StandardScaler()\n",
    "    Y_train_standard = yscaler.fit_transform(Y_train)\n",
    "    \n",
    "    Y_test_standard = yscaler.transform(Y_test)\n",
    "    \n",
    "    mlp = MLPRegressor()\n",
    "#     wapper = MultiOutputRegressor(mlp)\n",
    "    params = {\n",
    "        'hidden_layer_sizes':[(1,4), (2,2,4), (1,2,4)], \n",
    "        'activation':['logistic', 'tanh', 'relu'],\n",
    "        'max_iter':[5000],    \n",
    "        'solver':['lbfgs'],    \n",
    "        'learning_rate':['constant'],  \n",
    "        'random_state':[5]\n",
    "    }\n",
    "\n",
    "    total_iter = 20\n",
    "    #define partitioning\n",
    "    skf = RepeatedKFold(n_splits=5,random_state=22)\n",
    "    for baseEstimator in ['GP','RF','ET']:\n",
    "            opt = BayesSearchCV(estimator = mlp,\n",
    "            search_spaces=params,\n",
    "            n_iter=total_iter,n_jobs=-1,cv=skf,return_train_score=False,optimizer_kwargs={'base_estimator': baseEstimator})\n",
    "            report_perf(opt, X_train_standard, Y_train_standard,'BayesSearchCV_'+baseEstimator)\n",
    "\n",
    "    opt.fit(X_train_standard,  Y_train_standard)\n",
    "    best_model = opt.best_estimator_\n",
    "    \n",
    "    Cross_validation_MLP = cross_val_score(best_model, X_train_standard, Y_train_standard, cv=5)\n",
    "    Cross_validation_Accuracy_MLP = Cross_validation_MLP.mean().round(2)\n",
    "    Accuracy_MLP.append(Cross_validation_Accuracy_MLP)\n",
    "    Y_pred_MLP = best_model.predict(X_test_standard)\n",
    "    MLP_test_RMSE = sqrt(np.mean((Y_test_standard - Y_pred_MLP)**2))\n",
    "    \n",
    "    if  Cross_validation_Accuracy_MLP > Max_local:\n",
    "        Max_local = Cross_validation_Accuracy_MLP\n",
    "        Y_pred_MLP = best_model.predict(X_test_standard)\n",
    "        Y_pred_MLP_train = best_model.predict(X_train_standard)\n",
    "\n",
    "        Score_local = r2_score(Y_test_standard, Y_pred_MLP)\n",
    "        Score_local_train = r2_score(Y_train_standard, Y_pred_MLP_train)\n",
    "    \n",
    "    MLP_scores['CV'].append(Max_local)\n",
    "    MLP_scores['R2'].append(Score_local)\n",
    "    MLP_scores['R2_train'].append(Score_local_train)\n",
    "    \n",
    "    if Max_local > MaxGlobal and Score_local > MaxGlobal_Score and Score_local_train > MaxGlobal_Score_train:\n",
    "        MaxGlobal=Max_local\n",
    "        MaxGlobal_Score= Score_local\n",
    "        MaxGlobal_Score_train = Score_local_train\n",
    "        MLP_BestFit = best_model\n",
    "        MLP_BestFit_iter = (j)\n",
    "        print(MLP_BestFit_iter)\n",
    "        MLP_X_train_standard=X_train_standard\n",
    "        MLP_Y_train_standard=Y_train_standard\n",
    "        MLP_X_test_standard=X_test_standard\n",
    "        MLP_Y_test_standard=Y_test_standard\n",
    "        \n",
    "        MLP_Y_train_standard_realscale=yscaler.inverse_transform(Y_train_standard)\n",
    "        MLP_Y_test_standard_realscale=yscaler.inverse_transform(Y_test_standard)\n",
    "        ypredtrain=MLP_BestFit.predict(X_train_standard)\n",
    "        ypredtest=MLP_BestFit.predict(X_test_standard)\n",
    "        MLP_pred_Y_train_standard_realscale=yscaler.inverse_transform(ypredtrain)\n",
    "        MLP_pred_Y_test_standard_realscale=yscaler.inverse_transform(ypredtest)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MLP_BestFit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = pd.DataFrame(MLP_scores)\n",
    "\n",
    "print(\"CV = \", S.CV)\n",
    "print(\"R2 = \", S.R2)\n",
    "print(\"R2 train = \", S.R2_train)\n",
    "\n",
    "print(\"test r2 = {}\".format(r2_score(MLP_Y_test_standard_realscale,MLP_pred_Y_test_standard_realscale)))\n",
    "print(\"test RMSE: {0} and MAE: {1}\".format(sqrt(np.mean((MLP_Y_test_standard_realscale - MLP_pred_Y_test_standard_realscale)**2)),mae(MLP_Y_test_standard_realscale, MLP_pred_Y_test_standard_realscale).round(3)))\n",
    "\n",
    "print(\"train r2 = {}\".format(r2_score(MLP_Y_train_standard_realscale,MLP_pred_Y_train_standard_realscale)))\n",
    "print(\"train RMSE: {0} and MAE: {1}\".format(sqrt(np.mean((MLP_Y_train_standard_realscale - MLP_pred_Y_train_standard_realscale)**2)),mae(MLP_Y_train_standard_realscale, MLP_pred_Y_train_standard_realscale).round(3)))\n",
    "MLP_test_r2 = r2_score(MLP_Y_test_standard_realscale,MLP_pred_Y_test_standard_realscale)\n",
    "MLP_test_RMSE = sqrt(np.mean((MLP_Y_test_standard_realscale - MLP_pred_Y_test_standard_realscale)**2))\n",
    "MLP_train_r2 = r2_score(MLP_Y_train_standard_realscale, MLP_pred_Y_train_standard_realscale)\n",
    "MLP_train_RMSE = sqrt(np.mean((MLP_Y_train_standard_realscale - MLP_pred_Y_train_standard_realscale)**2))\n",
    "\n",
    "MLP_CV_Mean = S.CV.mean()\n",
    "joblib.dump(MLP_BestFit, './model/MLP_model.pkl')\n",
    "joblib.dump(xscaler, './model/MLP_Xscaler.pkl')\n",
    "joblib.dump(yscaler, './model/MLP_Yscaler.pkl')\n",
    "# Save data\n",
    "np.save('./model_data/MLP_Y_train_standard_realscale',MLP_Y_train_standard_realscale)\n",
    "np.save('./model_data/MLP_Y_test_standard_realscale',MLP_Y_test_standard_realscale)\n",
    "np.save('./model_data/MLP_pred_Y_train_standard_realscale',MLP_pred_Y_train_standard_realscale)\n",
    "np.save('./model_data/MLP_pred_Y_test_standard_realscale',MLP_pred_Y_test_standard_realscale)\n",
    "np.save('./model_data/MLP_X_train_standard',MLP_X_train_standard)\n",
    "np.save('./model_data/MLP_Y_train_standard',MLP_Y_train_standard)\n",
    "np.save('./model_data/MLP_X_test_standard',MLP_X_test_standard)\n",
    "np.save('./model_data/MLP_Y_test_standard',MLP_Y_test_standard)\n",
    "np.save('./model_data/MLP_scores',MLP_scores)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Validation DataSets\n",
    "'''\n",
    "file_name = 'Test_Phase.xlsx'\n",
    "dataset = pd.read_excel(file_name, header=0)\n",
    "#print(dataset)\n",
    "x1 = dataset['P(W)'].values\n",
    "x2 = dataset['V(mm/s)'].values\n",
    "x3 = dataset['h(um)'].values\n",
    "# x4 = dataset['t(um)'].values\n",
    "x5 = dataset['LED(J/mm)'].values\n",
    "# x6 = dataset['SED(J/mm2)'].values\n",
    "x7 = dataset['VED(J/mm3)'].values\n",
    "x8 = dataset['Ni'].values\n",
    "# x9 = dataset['Ti'].values\n",
    "x10 = dataset['Dmin'].values\n",
    "x11 = dataset['Dmax'].values\n",
    "x12 = dataset['D10'].values\n",
    "# x13 = dataset['D50'].values\n",
    "x14 = dataset['D90'].values\n",
    "\n",
    "\n",
    "y1 = dataset['Ms'].values\n",
    "y2 = dataset['Mf'].values\n",
    "y3 = dataset['As'].values\n",
    "y4 = dataset['Af'].values\n",
    "X = np.column_stack((x1.reshape(-1, 1), \n",
    "                     x2.reshape(-1, 1), \n",
    "                     x3.reshape(-1, 1),\n",
    "                #      x4.reshape(-1, 1), \n",
    "                     x5.reshape(-1, 1),\n",
    "                #      x6.reshape(-1, 1),\n",
    "                     x7.reshape(-1, 1),\n",
    "                     x8.reshape(-1, 1),\n",
    "                #      x9.reshape(-1, 1),\n",
    "                     x10.reshape(-1, 1),\n",
    "                     x11.reshape(-1, 1),\n",
    "                     x12.reshape(-1, 1),\n",
    "                #      x13.reshape(-1, 1),\n",
    "                     x14.reshape(-1, 1),\n",
    "               \n",
    "                     ))\n",
    "\n",
    "Y = np.column_stack((y1,y2, y3, y4))\n",
    "\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Validation DataSets\n",
    "'''\n",
    "x_standard = xscaler.transform(X)\n",
    "y_standard = yscaler.transform(Y)\n",
    "y_pre_standard = MLP_BestFit.predict(x_standard)\n",
    "y_pre_real = yscaler.inverse_transform(y_pre_standard)\n",
    "print(Y)\n",
    "print(y_pre_real.round(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "All DataSets\n",
    "'''\n",
    "file_name = 'NiTi_PhaseDatesets.xlsx'\n",
    "dataset = pd.read_excel(file_name, header=0)\n",
    "#print(dataset)\n",
    "x1 = dataset['P(W)'].values\n",
    "x2 = dataset['V(mm/s)'].values\n",
    "x3 = dataset['h(um)'].values\n",
    "# x4 = dataset['t(um)'].values\n",
    "x5 = dataset['LED(J/mm)'].values\n",
    "# x6 = dataset['SED(J/mm2)'].values\n",
    "x7 = dataset['VED(J/mm3)'].values\n",
    "x8 = dataset['Ni'].values\n",
    "# x9 = dataset['Ti'].values\n",
    "x10 = dataset['Dmin'].values\n",
    "x11 = dataset['Dmax'].values\n",
    "x12 = dataset['D10'].values\n",
    "# x13 = dataset['D50'].values\n",
    "x14 = dataset['D90'].values\n",
    "\n",
    "\n",
    "y1 = dataset['Ms'].values\n",
    "y2 = dataset['Mf'].values\n",
    "y3 = dataset['As'].values\n",
    "y4 = dataset['Af'].values\n",
    "all_X = np.column_stack((x1.reshape(-1, 1), \n",
    "                     x2.reshape(-1, 1), \n",
    "                     x3.reshape(-1, 1),\n",
    "                #      x4.reshape(-1, 1), \n",
    "                     x5.reshape(-1, 1),\n",
    "                #      x6.reshape(-1, 1),\n",
    "                     x7.reshape(-1, 1),\n",
    "                     x8.reshape(-1, 1),\n",
    "                #      x9.reshape(-1, 1),\n",
    "                     x10.reshape(-1, 1),\n",
    "                     x11.reshape(-1, 1),\n",
    "                     x12.reshape(-1, 1),\n",
    "                #      x13.reshape(-1, 1),\n",
    "                     x14.reshape(-1, 1),\n",
    "             \n",
    "                     ))\n",
    "\n",
    "all_Y = np.column_stack((y1,y2, y3, y4))\n",
    "\n",
    "\n",
    "print(len(all_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "All DataSets\n",
    "'''\n",
    "all_x_standard = xscaler.transform(all_X)\n",
    "all_y_standard = yscaler.transform(all_Y)\n",
    "all_y_pre_standard = MLP_BestFit.predict(all_x_standard)\n",
    "all_y_pre_real = yscaler.inverse_transform(all_y_pre_standard)\n",
    "print(all_Y)\n",
    "print(all_y_pre_real.round(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "All DataSets\n",
    "'''\n",
    "all_y_pre_real = all_y_pre_real.round(0)\n",
    "print(\"All DataSets r2 = {}\".format(r2_score(all_Y, all_y_pre_real)))\n",
    "print(\"All DataSets RMSE: {0} and MAE: {1}\".format(sqrt(np.mean((all_Y - all_y_pre_real)**2)),mae(all_Y, all_y_pre_real).round(3)))  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8809126b2e3f6bd67afd8dec0aaf136102c3339cf179547b748c69a78a732e29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
